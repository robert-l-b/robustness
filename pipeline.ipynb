{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import shutil\n",
    "from itertools import product \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "src_path = os.path.join(os.getcwd(), 'src')\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.log_stats_calculation import *\n",
    "from src.simulators.param_manipulation import *\n",
    "from src.sim_execution_and_evalaution import *\n",
    "from src.logging import log_simulation, initialize_simulation_log, save_params, set_up_experiment_output_dir, save_simulation_log, create_results_dataframe, save_results_dataframe\n",
    "from src.search_strategies.grid_search import run_grid_search\n",
    "from src.simulators.simod_discovery import discover_BPS_simod\n",
    "from src.pipeline_utils import get_params_to_change, set_target_val_and_range, prepare_simulation_files\n",
    "from src.evaluation import generate_and_plot_quadtree_metrics, plot_quadtree_metrics_over_depth, evaluate_quadtree_vs_simulation_log, evaluate_hyperquadtree_vs_simulation_log, compute_and_save_quadtree_metrics\n",
    "from src.search_strategies.quadtree import adaptive_quadtree, plot_quadtree, write_nodes_visited_to_json, write_quadtree_nodes_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prosimos import simulation_engine, simulation_properties_parser\n",
    "from simod.simulation.prosimos import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "process_name = 'LoanApp_SR'\n",
    "\n",
    "\n",
    "\n",
    "# target_ppis = ['lead_time']\n",
    "# target_ppis = ['cost']\n",
    "target_ppis = ['lead_time', 'cost']\n",
    "ppi_bounds = {\n",
    "    'lead_time': 'upper',\n",
    "    'cost': 'upper'\n",
    "}\n",
    "target_range = {\n",
    "    'lead_time': [0, 60*60*11],\n",
    "    'cost': [0, 60000]\n",
    "}\n",
    "\n",
    "ppi_range_factor = 0.2\n",
    "\n",
    "cases_to_simulate = 300\n",
    "discover_bps_model = False\n",
    "nr_simulations_per_scenario = 30\n",
    "execute_strategy = ['grid_search', 'hyperquadtree'] \n",
    "\n",
    "confidence = 0.9\n",
    "beta       = 0.85\n",
    "\n",
    "calculate_stats = 'custom'  # 'custom' or 'simod'\n",
    "dt = datetime.datetime(2025, 6, 23, 9, 0, tzinfo=datetime.timezone.utc)\n",
    "simulation_tool = 'simod'\n",
    "\n",
    "print_intermediate_results = True\n",
    "\n",
    "# internal parameters\n",
    "decimals = 3\n",
    "simulation_results_confidence = True\n",
    "in_out_criteria = \"confidence\"  # \"mean\" or \"confidence\"\n",
    "simod_config_path = 'simulators/simod/resources/config/config.yml'\n",
    "simod_directory = 'simulators/simod'\n",
    "ppi_calculation = {\n",
    "    'cost': {\n",
    "        'type': 'total',\n",
    "        'method': 'full_duration', # full_duration, active_time, combined\n",
    "        'weight': 1.5         # only applicable for 'combined' method\n",
    "    },\n",
    "    'lead_time': {\n",
    "        'type': 'avg'}\n",
    "    }\n",
    "update_parameters_list = ['resource_count', 'branching_probability']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parameters to change\n",
    "\n",
    "''''\n",
    "Possible values: \n",
    "    - continous (\"cont\"),\n",
    "    - discrete (\"disc\"), \n",
    "    - categorical (\"cat\").\n",
    "\n",
    "Define ranges for each parameter:\n",
    "    - continuous: [min, max]    \n",
    "    - discrete: [min, max]\n",
    "    - categorical: [list of possible values]\n",
    "'''\n",
    "\n",
    "input_parameters = {\n",
    "    'arriaval_distr_mean': {\n",
    "        'type': 'cont',\n",
    "        'values': [0, 60*60*2 + 250], \n",
    "        'min_step_size': 60*2.5  \n",
    "    },  \n",
    "    'resource_count': {\n",
    "        'type': 'disc',\n",
    "        'values': [1, 20],  # 1 to 26 resources\n",
    "        'ignore': ['applicant'],\n",
    "        'min_step_size': 1\n",
    "    },\n",
    "    # 'branching_probability': {\n",
    "    #     'type': 'cont',\n",
    "    #     'values': [0, 1],  # 0% to 100%,\n",
    "    #     # 'ignore': ['node_645ee027-7ae8-4f3a-9127-f99918deb220'], # Ignore all of these gateways\n",
    "    #     'use':    ['node_51629ebf-d0e1-49e5-ac00-74cb1ead72c6'],  # If given, only use these gateways\n",
    "    #     'min_step_size': 0.1\n",
    "    # }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write inputs into \n",
    "base_path = os.path.join('data', process_name)\n",
    "\n",
    "dt_str = dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "params= {}\n",
    "\n",
    "params = {\n",
    "    'process_name': process_name,\n",
    "    'base_path': base_path,\n",
    "    'target_ppis': target_ppis,\n",
    "    \n",
    "    'ppi_bounds': ppi_bounds,\n",
    "    'ppi_range_factor': ppi_range_factor,\n",
    "    'cases_to_simulate': cases_to_simulate,\n",
    "    'starting_at':dt_str,\n",
    "    'simulation_tool': simulation_tool,\n",
    "    'nr_simulations_per_scenario': nr_simulations_per_scenario,\n",
    "    'decimals': decimals,\n",
    "    'simulation_results_confidence': simulation_results_confidence,\n",
    "    'calculate_stats': calculate_stats,\n",
    "    'confidence': confidence,\n",
    "    'beta': beta,\n",
    "    'in_out_criteria': in_out_criteria,\n",
    "    'print_intermediate_results': print_intermediate_results,\n",
    "    'execute_strategy': execute_strategy,\n",
    "    'simod_config_path': simod_config_path,\n",
    "    'simod_directory': simod_directory,\n",
    "    'ppi_calculation': ppi_calculation,\n",
    "    'input_parameters': input_parameters,\n",
    "    'update_parameters_list': update_parameters_list\n",
    "}\n",
    "\n",
    "if 'target_range' in locals():\n",
    "   params['target_range'] = target_range\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params['strategies'] = {\n",
    "    'grid_search': {\n",
    "        # 'granularity': 25,\n",
    "        'input': 'max_granularity' \n",
    "    },\n",
    "    'hyperquadtree': {\n",
    "        'min_depth': 3,\n",
    "        'max_depth': 8,\n",
    "        'variation': ['midpoints']  # 'random' or 'midpoints' 'random', \n",
    "    },\n",
    "    'quadtree': {\n",
    "        'min_depth': 3,\n",
    "        'max_depth': 6\n",
    "    },\n",
    "    'diagonal_search': {\n",
    "        'stepsize_initial': 0.1,\n",
    "        'step_max': 20,\n",
    "        'adaptive_step': True,\n",
    "        'strictness': 0.01\n",
    "    },\n",
    "    'hill_climbing': {\n",
    "        'stepsize_initial': 0.1,\n",
    "        'step_max': 20,\n",
    "        # 'adaptive_step': True,\n",
    "        'candidate_strategy': 'random_one',\n",
    "        'walk_reps_max': 100\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implement automatic calling of discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if discover_bps_model:\n",
    "\n",
    "    discover_BPS_simod(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params = prepare_simulation_files(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPMN plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your PNG file\n",
    "name = params['process_name']\n",
    "image_path = os.path.join(params['base_path'],  f'{name}.png')\n",
    "\n",
    "try:\n",
    "    # Load and display the image\n",
    "    img = mpimg.imread(image_path)\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Turn off the axis\n",
    "    plt.show()\n",
    "except:\n",
    "    print(f\"Image file not found at {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation based on input ranges and parameters to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add params_to_change to params dictionary\n",
    "params['params_to_change'] = get_params_to_change(params)\n",
    "# Initialize a global DataFrame to store simulation logs\n",
    "simulation_log = initialize_simulation_log(params['params_to_change'])\n",
    "\n",
    "# Create the DataFrame\n",
    "results_df = create_results_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up experiment output directory\n",
    "params = set_up_experiment_output_dir(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if target range is not defined, set it here\n",
    "if 'target_range' not in params:\n",
    "\n",
    "    params = set_target_val_and_range(params)\n",
    "\n",
    "    simulation_log = log_simulation(\n",
    "        simulation_log=simulation_log,\n",
    "        algorithm='orig_run',\n",
    "        params=params,\n",
    "        # target_ppi_dict=params['orig_target_ppi_val_dict'],\n",
    "        target_ppi_dict=params['target_ppi_dict'],\n",
    "        param_values=get_start_param_settings(params['params_to_change'], params),\n",
    "    )\n",
    "else:\n",
    "    print(\"Use predefined Target PPI ranges.\")\n",
    "\n",
    "print('''\\n#############################\\n###  Intermediate output  ###''')\n",
    "for ppi in params['target_ppis']:\n",
    "    try:\n",
    "        val = params['orig_target_ppi_val_dict'][ppi]   \n",
    "        print(f'average {ppi}: {val}')\n",
    "    except:\n",
    "        pass\n",
    "    val = params['target_range'][ppi]\n",
    "    print(f'range: {val}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save paramas to json file in data/process_name/output/params.json\n",
    "save_params(params)\n",
    "\n",
    "# Write simulation log to CSV\n",
    "save_simulation_log(simulation_log, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%time\n",
    "\n",
    "if 'grid_search' in params['execute_strategy']:\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    simulation_log = run_grid_search(params, simulation_log=simulation_log)\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    save_simulation_log(simulation_log, params)\n",
    "\n",
    "    result = pd.DataFrame([{\n",
    "        'experiment': params.get('experiment_name', None),\n",
    "        'algorithm': 'grid_search',\n",
    "        'evals': len(simulation_log[simulation_log['algorithm'] == 'grid_search']),\n",
    "        'time': elapsed_time,\n",
    "        'n': params['nr_simulations_per_scenario'],\n",
    "        'n_total': len(simulation_log[simulation_log['algorithm'] == 'grid_search']) * params['nr_simulations_per_scenario'],\n",
    "        'acc': '-',   \n",
    "        'mcc': '-'    \n",
    "    }])\n",
    "    # Append the new row to the DataFrame\n",
    "    results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_count = simulation_log[simulation_log[\"status\"] == True].shape[0]\n",
    "print(f\"Number of simulation scenarios inside PPI range: {success_count}\")\n",
    "failed_count = simulation_log[simulation_log[\"status\"] == False].shape[0]\n",
    "print(f\"Number of simulation scenarios outside PPI range: {failed_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hill Climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'hill_cimbing' in params['execute_strategy']:\n",
    "\n",
    "    from src.search_strategies.hill_climbing import hill_descent\n",
    "\n",
    "    # Reset the temp JSON file\n",
    "    create_temp_json(input_path=params['json_path'], output_path=None)\n",
    "\n",
    "    stepsize_initial = params['strategies']['hill_climbing']['stepsize_initial']\n",
    "    step_max = params['strategies']['hill_climbing']['step_max']\n",
    "    candidate_strategy = params['strategies']['hill_climbing']['candidate_strategy']\n",
    "    walk_reps_max = params['strategies']['hill_climbing']['walk_reps_max'] \n",
    "\n",
    "    # Call the hill descent function\n",
    "    hill_descent(\n",
    "        params, \n",
    "        step_size_initial=stepsize_initial, \n",
    "        step_max=step_max, \n",
    "        params_to_change=params_to_change, \n",
    "        candidate_strategy=candidate_strategy, \n",
    "        walk_reps_max=walk_reps_max\n",
    "        )\n",
    "\n",
    "    # Save the simulation log to a CSV file for later analysis\n",
    "    simulation_log.to_csv(params['simulation_log_path'], index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hpyerquadtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.search_strategies.hyperquadtree import adaptive_hyperquadtree, write_hyperquadtree_nodes_to_file, write_nodes_visited_to_json\n",
    "\n",
    "if 'hyperquadtree' in params['execute_strategy']:\n",
    "\n",
    "\n",
    "    min_depth = params['strategies']['hyperquadtree']['min_depth']\n",
    "    max_depth = params['strategies']['hyperquadtree']['max_depth']\n",
    "\n",
    "    variations = params['strategies']['hyperquadtree'].get('variation', 'midpoints')\n",
    "\n",
    "    for variation in variations:\n",
    "\n",
    "        algorithm = 'hyperquadtree'\n",
    "        algorithm_name = f'{algorithm}_{variation}'\n",
    "\n",
    "        # Reset the temp JSON file\n",
    "        create_temp_json(input_path=params['json_path'], output_path=None)\n",
    "\n",
    "        # Start the timer\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Call the hyperquadtree function\n",
    "        all_nodes, sampled_points, nodes_visited, simulation_log = adaptive_hyperquadtree(\n",
    "            set_sim_params_get_sim_stats,\n",
    "            is_in_target_range,\n",
    "            params,\n",
    "            simulation_log,\n",
    "            min_depth=min_depth,\n",
    "            max_depth=max_depth,\n",
    "            variation=variation\n",
    "        )\n",
    "\n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "\n",
    "        # log results\n",
    "        save_simulation_log(simulation_log, params)\n",
    "\n",
    "        params['strategies']['hyperquadtree']['paths'] = {}\n",
    "        params['strategies']['hyperquadtree']['paths']['sampled_points'] = os.path.join(params['experiment_output_dir'], 'hyperquadtree_sampled_points.csv')\n",
    "        params['strategies']['hyperquadtree']['paths']['nodes_visited'] = os.path.join(params['experiment_output_dir'], 'hyperquadtree_nodes_visited.csv')\n",
    "        if params['print_intermediate_results']:\n",
    "            print(params['strategies']['hyperquadtree']['paths'])\n",
    "        \n",
    "        save_params(params)\n",
    "        write_hyperquadtree_nodes_to_file(all_nodes, params)\n",
    "        write_nodes_visited_to_json(nodes_visited, params)\n",
    "\n",
    "        max_depth_reached = len(nodes_visited)\n",
    "\n",
    "        results_hqt = compute_and_save_quadtree_metrics(all_nodes, \n",
    "                                        simulation_log, \n",
    "                                        params, \n",
    "                                        nodes_visited, \n",
    "                                        max_depth=max_depth_reached, \n",
    "                                        algorithm=algorithm, \n",
    "                                        output_file_name='hyperquadtree_metrics_over_depth.csv'\n",
    "                                        )\n",
    "\n",
    "        final_hqt_iteration = results_hqt.iloc[-1, :]\n",
    "\n",
    "        result = pd.DataFrame([{\n",
    "            'experiment': exp_name, #params.get('experiment_name', None),\n",
    "            'algorithm': algorithm_name,\n",
    "            'evals': final_hqt_iteration['nodes_computed'],\n",
    "            'time': np.round(elapsed_time, params['decimals']),\n",
    "            'n': params['nr_simulations_per_scenario'],\n",
    "            'n_total': len(simulation_log[simulation_log['algorithm'] == 'hyperquadtree']) * params['nr_simulations_per_scenario'],\n",
    "            'acc': np.round(final_hqt_iteration['accuracy'], params['decimals']),   \n",
    "            'mcc': np.round(final_hqt_iteration['mcc'], params['decimals'])\n",
    "        }])\n",
    "        results_df = pd.concat([results_df, result], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results_dataframe(results_df, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'hyperquadtree' in params['execute_strategy']:\n",
    "    display(results_hqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the time column into minutes with one decimal\n",
    "results_df['time_minutes'] = (results_df['time'] / 60).round(1)\n",
    "colums_to_show = ['experiment', 'algorithm', 'evals', 'time_minutes', 'acc', 'mcc']\n",
    "results_df[colums_to_show]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
